{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10回講義 演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "trng = RandomStreams(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1. [Scan](http://deeplearning.net/software/theano/library/scan.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theanoではループのためにfor文ではなく, Scan というものを使います.  \n",
    "少しややこしいので, 簡単な例を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#- Suppose you have a sequence [1, 2, 3, 4, 5] let's define indentity function with scan\n",
    "x = T.fvector('x')\n",
    "\n",
    "def step(x):\n",
    "    return x\n",
    "\n",
    "h, _ = theano.scan(fn=step,\n",
    "                         sequences=x,\n",
    "                         outputs_info=None)\n",
    "\n",
    "func = theano.function(inputs=[x], outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(np.array([1, 2, 3, 4, 5], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#- Next we define accumulation function\n",
    "x = T.fvector('x')\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(fn=step,\n",
    "                         sequences=x,\n",
    "                         outputs_info=0.0)\n",
    "\n",
    "func = theano.function(inputs=[x], outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   3.,   6.,  10.,  15.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(np.array([1, 2, 3, 4, 5], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#- Let's do the same thing with matrix, accumulation over column\n",
    "x = T.fmatrix('x')\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(fn=step,\n",
    "                         sequences=x,\n",
    "                         outputs_info=np.zeros(5, dtype='float32'))\n",
    "\n",
    "func = theano.function(inputs=[x], outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.,   4.,   5.],\n",
       "       [  2.,   4.,   6.,   8.,  10.],\n",
       "       [  3.,   6.,   9.,  12.,  15.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(np.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#- Advanced :: take previous inputs\n",
    "x = T.fmatrix('x')\n",
    "\n",
    "def step(x, h_tm1, h_tm2):\n",
    "    return x + h_tm1 + h_tm2\n",
    "\n",
    "h, _ = theano.scan(fn=step,\n",
    "                         sequences=[dict(input=x, taps=[0, -1, -2])],\n",
    "                         outputs_info=None)\n",
    "\n",
    "func = theano.function(inputs=[x], outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,   6.,   9.,  12.,  15.],\n",
       "       [  3.,   6.,   9.,  12.,  15.],\n",
       "       [  3.,   6.,   9.,  12.,  15.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(np.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]], dtype='float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題2. Recurrent Neural Network (RNN) で Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文が与えられた時, その品詞を予測するRNNを学習します.\n",
    "\n",
    "word2indexは単語をIDに変換する辞書, tag2indexは品詞をIDに変換する辞書です.  \n",
    "train_data, valid_dataには文と品詞タグのペアが入っています.  \n",
    "文の長さと品詞タグの長さは必ず同じです.\n",
    "\n",
    "encode_datasetを使うと単語と品詞をIDに変換することができます."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データセットの読み込みと単語・品詞のID化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    dataset = []\n",
    "    vocab, tag = set(), set()\n",
    "    for line in open(file_path):\n",
    "        instance = [l.strip().split() for l in line.split('|||')]\n",
    "        vocab.update(instance[0])\n",
    "        tag.update(instance[1])\n",
    "        dataset.append(instance)\n",
    "    return dataset, vocab, tag\n",
    "\n",
    "def encode_dataset(dataset, word2index, tag2index):\n",
    "    X, y = [], []\n",
    "    vocab = set(word2index.keys())\n",
    "    for sentence, tags in dataset:\n",
    "        X.append([word2index[word] if word in vocab else word2index['<unk>'] for word in sentence])\n",
    "        y.append([tag2index[tag] for tag in tags])\n",
    "    return X, y\n",
    "\n",
    "train_data, train_vocab, train_tags = load_data('train.unk')\n",
    "special_words = set(['<unk>'])\n",
    "\n",
    "word2index = dict(map(lambda x: (x[1], x[0]), enumerate(train_vocab | special_words)))\n",
    "tag2index  = dict(map(lambda x: (x[1], x[0]), enumerate(train_tags)))\n",
    "\n",
    "train_X, train_y = encode_dataset(train_data, word2index, tag2index)\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "教師ラベルのone-hot化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = np.arange(len(tag2index))\n",
    "train_y = [label_binarize(instance_y, classes).astype('int32') for instance_y in train_y]\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "今回の入力は単語のID列（ベクトルx）と品詞のID列（ベクトルy）です.  \n",
    "Projectionレイヤーを使って, 単語をベクトルに変換します.  \n",
    "その後, RNNに入力し, その出力値をSoftmax関数を使って確率分布に変換します.  \n",
    "予測は画像の時とおなじく, 最大の確率を持つクラスを予測とします."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 単語のEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sharedX(X, name='', dtype=\"float32\"):\n",
    "    return theano.shared(np.array(X, dtype=dtype), name=name)\n",
    "\n",
    "class Projection:\n",
    "    def __init__(self, in_dim, out_dim, scale):\n",
    "        self.V = sharedX(rng.randn(in_dim, out_dim) * scale, name='V')\n",
    "        self.params = [self.V]\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        x_emb = self.V[x]\n",
    "        return x_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, in_dim, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "\n",
    "        #- 重みの次元を決める\n",
    "        self.W_in  = sharedX(rng.randn(in_dim, hid_dim) * np.sqrt(2./in_dim), name='W_in')\n",
    "        self.W_rec = sharedX(rng.randn(hid_dim, hid_dim) * np.sqrt(2./hid_dim), name='W_rec')\n",
    "        # consider how to initialize b\n",
    "        self.b_rec = sharedX(np.zeros(hid_dim), name='b_rec')\n",
    "        self.h_0   = sharedX(np.zeros(hid_dim), name='h_0')\n",
    "\n",
    "        self.output_info = [self.h_0]\n",
    "        self.params = [self.W_in, self.W_rec, self.b_rec]\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        def step(x, h_tm1):\n",
    "            h = T.dot(x, self.W_in) + T.dot(h_tm1, self.W_rec) + self.b_rec\n",
    "            return h\n",
    "\n",
    "        #- Scanの方法を考える\n",
    "        h, _ = theano.scan(fn=step,\n",
    "                         sequences=[x],\n",
    "                         outputs_info=self.output_info)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 線形層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.W_out = sharedX(rng.randn(in_dim, out_dim) * np.sqrt(2./in_dim), name='W_out')\n",
    "        self.b_out = sharedX(np.zeros(out_dim), name='b_out')\n",
    "        self.params = [self.W_out, self.b_out]\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        z = T.dot(x, self.W_out) + self.b_out\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 活性化層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "        self.params = []\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        self.z = self.function(x)\n",
    "        return self.z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 更新則"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(cost, params, eps=np.float32(0.001)):\n",
    "    gparams = T.grad(cost, params)\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        #- Advanced Gradient Clipを実装する（必須ではない）\n",
    "        gnorm = gparam.norm(L=2)\n",
    "        gparam = 5. / gnorm * gparam\n",
    "        updates[param] = param - eps*gparam\n",
    "    return updates\n",
    "\n",
    "def Adam(params, g_params, lr=0.001, b1=0.1, b2=0.001, e=1e-4):\n",
    "    updates = []\n",
    "    i = theano.shared(np.float32(0.))\n",
    "    i_t = i + 1.\n",
    "    fix1 = 1. - (1. - b1)**i_t\n",
    "    fix2 = 1. - (1. - b2)**i_t\n",
    "    lr_t = lr * (T.sqrt(fix2) / fix1)\n",
    "    for p, g in zip(params, g_params):\n",
    "        #- Advanced Gradient Clipを実装する（必須ではない）\n",
    "        gnorm = g.norm(L=2)\n",
    "        g = 5. / gnorm * g\n",
    "        m = theano.shared(p.get_value() * 0.)\n",
    "        v = theano.shared(p.get_value() * 0.)\n",
    "        m_t = (b1 * g) + ((1. - b1) * m)\n",
    "        v_t = (b2 * T.sqr(g)) + ((1. - b2) * v)\n",
    "        g_t = m_t / (T.sqrt(v_t) + e)\n",
    "        p_t = p - (lr_t * g_t)\n",
    "        updates.append((m, m_t))\n",
    "        updates.append((v, v_t))\n",
    "        updates.append((p, p_t))\n",
    "    updates.append((i, i_t))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word2index)\n",
    "hid_dim    = 500\n",
    "out_dim    = len(tag2index)\n",
    "\n",
    "x = T.ivector('x')\n",
    "t = T.imatrix('t')\n",
    "\n",
    "layers = [\n",
    "    Projection(vocab_size, 500, scale=0.1),\n",
    "    RNN(500, hid_dim),\n",
    "    Activation(T.nnet.sigmoid),\n",
    "    Linear(hid_dim, out_dim),\n",
    "    Activation(T.nnet.softmax)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. train関数とvalid関数とtest関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "layer_out = x\n",
    "for i, layer in enumerate(layers):\n",
    "    params += layer.params\n",
    "    if i == 0:\n",
    "        layer_out = layer.f_prop(x)\n",
    "    else:\n",
    "        layer_out = layer.f_prop(layer_out)\n",
    "\n",
    "y = layers[-1].z\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y, t))\n",
    "gparams = T.grad(cost, params)\n",
    "\n",
    "## Define update graph\n",
    "updates = Adam(params, gparams, lr=9e-4, e=1e-2) \n",
    "\n",
    "## Compile Function\n",
    "train = theano.function(inputs=[x,t], outputs=cost, updates=updates)\n",
    "valid = theano.function(inputs=[x,t], outputs=[cost, T.argmax(y, axis=1)])\n",
    "test  = theano.function(inputs=[x], outputs=T.argmax(y, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 1, Iteration 0, cost: 4.177\n",
      "used time: 0.031\n",
      "EPOCH:: 1, Iteration 1000, cost: 3.383\n",
      "used time: 22.463\n",
      "EPOCH:: 1, Iteration 2000, cost: 2.873\n",
      "used time: 22.467\n",
      "EPOCH:: 1, Iteration 3000, cost: 1.281\n",
      "used time: 22.513\n",
      "EPOCH:: 1, Iteration 4000, cost: 0.819\n",
      "used time: 22.536\n",
      "EPOCH:: 1, Iteration 5000, cost: 1.351\n",
      "used time: 22.558\n",
      "EPOCH:: 1, Iteration 6000, cost: 0.354\n",
      "used time: 22.535\n",
      "EPOCH:: 1, Iteration 7000, cost: 0.894\n",
      "used time: 22.233\n",
      "EPOCH:: 1, Iteration 8000, cost: 0.191\n",
      "used time: 22.089\n",
      "EPOCH:: 1, Iteration 9000, cost: 0.076\n",
      "used time: 22.125\n",
      "EPOCH:: 1, Iteration 10000, cost: 0.278\n",
      "used time: 22.107\n",
      "EPOCH:: 1, Iteration 11000, cost: 0.039\n",
      "used time: 22.143\n",
      "EPOCH:: 1, Iteration 12000, cost: 0.392\n",
      "used time: 22.125\n",
      "EPOCH:: 1, Iteration 13000, cost: 0.015\n",
      "used time: 22.227\n",
      "EPOCH:: 1, Iteration 14000, cost: 0.049\n",
      "used time: 22.223\n",
      "EPOCH:: 1, Iteration 15000, cost: 0.222\n",
      "used time: 22.449\n",
      "EPOCH:: 1, Iteration 16000, cost: 0.164\n",
      "used time: 22.283\n",
      "EPOCH:: 1, Iteration 17000, cost: 0.052\n",
      "used time: 22.262\n",
      "EPOCH:: 1, Iteration 18000, cost: 0.449\n",
      "used time: 22.271\n",
      "EPOCH:: 1, Iteration 19000, cost: 0.235\n",
      "used time: 22.286\n",
      "EPOCH:: 1, Iteration 20000, cost: 0.189\n",
      "used time: 22.342\n",
      "EPOCH:: 1, Iteration 21000, cost: 0.399\n",
      "used time: 22.305\n",
      "EPOCH:: 1, Iteration 22000, cost: 0.126\n",
      "used time: 22.319\n",
      "EPOCH:: 1, Iteration 23000, cost: 0.062\n",
      "used time: 22.342\n",
      "EPOCH:: 1, Iteration 24000, cost: 0.301\n",
      "used time: 22.372\n",
      "EPOCH:: 1, Iteration 25000, cost: 0.283\n",
      "used time: 22.326\n",
      "EPOCH:: 1, Validation cost: 0.000, Validation F1: 0.798\n",
      "EPOCH:: 2, Iteration 0, cost: 0.348\n",
      "used time: 0.032\n",
      "EPOCH:: 2, Iteration 1000, cost: 0.076\n",
      "used time: 22.291\n",
      "EPOCH:: 2, Iteration 2000, cost: 0.118\n",
      "used time: 22.367\n",
      "EPOCH:: 2, Iteration 3000, cost: 0.153\n",
      "used time: 22.359\n",
      "EPOCH:: 2, Iteration 4000, cost: 0.023\n",
      "used time: 22.340\n",
      "EPOCH:: 2, Iteration 5000, cost: 0.000\n",
      "used time: 22.326\n",
      "EPOCH:: 2, Iteration 6000, cost: 0.312\n",
      "used time: 22.342\n",
      "EPOCH:: 2, Iteration 7000, cost: 0.322\n",
      "used time: 22.363\n",
      "EPOCH:: 2, Iteration 8000, cost: 0.149\n",
      "used time: 22.290\n",
      "EPOCH:: 2, Iteration 9000, cost: 0.385\n",
      "used time: 22.341\n",
      "EPOCH:: 2, Iteration 10000, cost: 0.009\n",
      "used time: 22.353\n",
      "EPOCH:: 2, Iteration 11000, cost: 0.120\n",
      "used time: 22.357\n",
      "EPOCH:: 2, Iteration 12000, cost: 0.316\n",
      "used time: 22.320\n",
      "EPOCH:: 2, Iteration 13000, cost: 0.004\n",
      "used time: 22.317\n",
      "EPOCH:: 2, Iteration 14000, cost: 0.026\n",
      "used time: 22.297\n",
      "EPOCH:: 2, Iteration 15000, cost: 0.000\n",
      "used time: 22.343\n",
      "EPOCH:: 2, Iteration 16000, cost: 0.003\n",
      "used time: 22.319\n",
      "EPOCH:: 2, Iteration 17000, cost: 0.287\n",
      "used time: 22.290\n",
      "EPOCH:: 2, Iteration 18000, cost: 0.488\n",
      "used time: 22.290\n",
      "EPOCH:: 2, Iteration 19000, cost: 0.020\n",
      "used time: 22.350\n",
      "EPOCH:: 2, Iteration 20000, cost: 0.025\n",
      "used time: 22.321\n",
      "EPOCH:: 2, Iteration 21000, cost: 0.770\n",
      "used time: 22.321\n",
      "EPOCH:: 2, Iteration 22000, cost: 0.324\n",
      "used time: 22.324\n",
      "EPOCH:: 2, Iteration 23000, cost: 0.141\n",
      "used time: 22.271\n",
      "EPOCH:: 2, Iteration 24000, cost: 0.522\n",
      "used time: 22.290\n",
      "EPOCH:: 2, Iteration 25000, cost: 0.038\n",
      "used time: 22.337\n",
      "EPOCH:: 2, Validation cost: 0.000, Validation F1: 0.808\n",
      "EPOCH:: 3, Iteration 0, cost: 0.247\n",
      "used time: 0.032\n",
      "EPOCH:: 3, Iteration 1000, cost: 0.019\n",
      "used time: 22.304\n",
      "EPOCH:: 3, Iteration 2000, cost: 0.059\n",
      "used time: 22.294\n",
      "EPOCH:: 3, Iteration 3000, cost: 0.001\n",
      "used time: 22.326\n",
      "EPOCH:: 3, Iteration 4000, cost: 0.000\n",
      "used time: 22.387\n",
      "EPOCH:: 3, Iteration 5000, cost: 0.132\n",
      "used time: 22.335\n",
      "EPOCH:: 3, Iteration 6000, cost: 0.258\n",
      "used time: 22.348\n",
      "EPOCH:: 3, Iteration 7000, cost: 0.002\n",
      "used time: 22.359\n",
      "EPOCH:: 3, Iteration 8000, cost: 0.000\n",
      "used time: 22.281\n",
      "EPOCH:: 3, Iteration 9000, cost: 0.237\n",
      "used time: 22.301\n",
      "EPOCH:: 3, Iteration 10000, cost: 0.003\n",
      "used time: 22.315\n",
      "EPOCH:: 3, Iteration 11000, cost: 0.283\n",
      "used time: 22.334\n",
      "EPOCH:: 3, Iteration 12000, cost: 0.067\n",
      "used time: 22.339\n",
      "EPOCH:: 3, Iteration 13000, cost: 0.087\n",
      "used time: 22.326\n",
      "EPOCH:: 3, Iteration 14000, cost: 0.001\n",
      "used time: 22.329\n",
      "EPOCH:: 3, Iteration 15000, cost: 0.006\n",
      "used time: 22.325\n",
      "EPOCH:: 3, Iteration 16000, cost: 0.014\n",
      "used time: 22.322\n",
      "EPOCH:: 3, Iteration 17000, cost: 0.425\n",
      "used time: 22.339\n",
      "EPOCH:: 3, Iteration 18000, cost: 0.148\n",
      "used time: 22.323\n",
      "EPOCH:: 3, Iteration 19000, cost: 0.030\n",
      "used time: 22.311\n",
      "EPOCH:: 3, Iteration 20000, cost: 0.967\n",
      "used time: 22.312\n",
      "EPOCH:: 3, Iteration 21000, cost: 0.001\n",
      "used time: 22.312\n",
      "EPOCH:: 3, Iteration 22000, cost: 0.397\n",
      "used time: 22.331\n",
      "EPOCH:: 3, Iteration 23000, cost: 0.758\n",
      "used time: 22.323\n",
      "EPOCH:: 3, Iteration 24000, cost: 0.001\n",
      "used time: 22.324\n",
      "EPOCH:: 3, Iteration 25000, cost: 0.109\n",
      "used time: 22.323\n",
      "EPOCH:: 3, Validation cost: 0.000, Validation F1: 0.816\n",
      "EPOCH:: 4, Iteration 0, cost: 0.105\n",
      "used time: 0.031\n",
      "EPOCH:: 4, Iteration 1000, cost: 0.566\n",
      "used time: 22.341\n",
      "EPOCH:: 4, Iteration 2000, cost: 0.006\n",
      "used time: 22.311\n",
      "EPOCH:: 4, Iteration 3000, cost: 0.055\n",
      "used time: 22.309\n",
      "EPOCH:: 4, Iteration 4000, cost: 0.009\n",
      "used time: 22.318\n",
      "EPOCH:: 4, Iteration 5000, cost: 0.003\n",
      "used time: 22.314\n",
      "EPOCH:: 4, Iteration 6000, cost: 0.000\n",
      "used time: 22.295\n",
      "EPOCH:: 4, Iteration 7000, cost: 0.520\n",
      "used time: 22.345\n",
      "EPOCH:: 4, Iteration 8000, cost: 0.139\n",
      "used time: 22.333\n",
      "EPOCH:: 4, Iteration 9000, cost: 0.036\n",
      "used time: 22.311\n",
      "EPOCH:: 4, Iteration 10000, cost: 0.034\n",
      "used time: 22.403\n",
      "EPOCH:: 4, Iteration 11000, cost: 0.312\n",
      "used time: 22.279\n",
      "EPOCH:: 4, Iteration 12000, cost: 0.000\n",
      "used time: 22.312\n",
      "EPOCH:: 4, Iteration 13000, cost: 0.096\n",
      "used time: 22.360\n",
      "EPOCH:: 4, Iteration 14000, cost: 0.000\n",
      "used time: 22.324\n",
      "EPOCH:: 4, Iteration 15000, cost: 0.030\n",
      "used time: 22.319\n",
      "EPOCH:: 4, Iteration 16000, cost: 0.727\n",
      "used time: 22.311\n",
      "EPOCH:: 4, Iteration 17000, cost: 0.002\n",
      "used time: 22.308\n",
      "EPOCH:: 4, Iteration 18000, cost: 0.201\n",
      "used time: 22.312\n",
      "EPOCH:: 4, Iteration 19000, cost: 0.097\n",
      "used time: 22.318\n",
      "EPOCH:: 4, Iteration 20000, cost: 0.025\n",
      "used time: 22.323\n",
      "EPOCH:: 4, Iteration 21000, cost: 0.001\n",
      "used time: 22.267\n",
      "EPOCH:: 4, Iteration 22000, cost: 0.439\n",
      "used time: 22.297\n",
      "EPOCH:: 4, Iteration 23000, cost: 0.304\n",
      "used time: 22.334\n",
      "EPOCH:: 4, Iteration 24000, cost: 0.174\n",
      "used time: 22.314\n",
      "EPOCH:: 4, Iteration 25000, cost: 1.138\n",
      "used time: 22.270\n",
      "EPOCH:: 4, Validation cost: 0.000, Validation F1: 0.833\n",
      "EPOCH:: 5, Iteration 0, cost: 0.023\n",
      "used time: 0.030\n",
      "EPOCH:: 5, Iteration 1000, cost: 0.104\n",
      "used time: 22.334\n",
      "EPOCH:: 5, Iteration 2000, cost: 0.236\n",
      "used time: 22.318\n",
      "EPOCH:: 5, Iteration 3000, cost: 0.421\n",
      "used time: 22.334\n",
      "EPOCH:: 5, Iteration 4000, cost: 0.357\n",
      "used time: 22.331\n",
      "EPOCH:: 5, Iteration 5000, cost: 0.011\n",
      "used time: 22.304\n",
      "EPOCH:: 5, Iteration 6000, cost: 0.000\n",
      "used time: 22.309\n",
      "EPOCH:: 5, Iteration 7000, cost: 0.463\n",
      "used time: 22.325\n",
      "EPOCH:: 5, Iteration 8000, cost: 0.001\n",
      "used time: 22.346\n",
      "EPOCH:: 5, Iteration 9000, cost: 0.162\n",
      "used time: 22.311\n",
      "EPOCH:: 5, Iteration 10000, cost: 0.566\n",
      "used time: 22.271\n",
      "EPOCH:: 5, Iteration 11000, cost: 0.000\n",
      "used time: 22.308\n",
      "EPOCH:: 5, Iteration 12000, cost: 0.006\n",
      "used time: 22.272\n",
      "EPOCH:: 5, Iteration 13000, cost: 0.151\n",
      "used time: 22.315\n",
      "EPOCH:: 5, Iteration 14000, cost: 0.065\n",
      "used time: 22.278\n",
      "EPOCH:: 5, Iteration 15000, cost: 0.001\n",
      "used time: 22.270\n",
      "EPOCH:: 5, Iteration 16000, cost: 0.001\n",
      "used time: 22.330\n",
      "EPOCH:: 5, Iteration 17000, cost: 0.000\n",
      "used time: 22.349\n",
      "EPOCH:: 5, Iteration 18000, cost: 0.000\n",
      "used time: 22.330\n",
      "EPOCH:: 5, Iteration 19000, cost: 0.076\n",
      "used time: 22.311\n",
      "EPOCH:: 5, Iteration 20000, cost: 0.003\n",
      "used time: 22.296\n",
      "EPOCH:: 5, Iteration 21000, cost: 0.001\n",
      "used time: 22.361\n",
      "EPOCH:: 5, Iteration 22000, cost: 0.006\n",
      "used time: 22.300\n",
      "EPOCH:: 5, Iteration 23000, cost: 0.110\n",
      "used time: 22.297\n",
      "EPOCH:: 5, Iteration 24000, cost: 0.000\n",
      "used time: 22.311\n",
      "EPOCH:: 5, Iteration 25000, cost: 0.002\n",
      "used time: 22.333\n",
      "EPOCH:: 5, Validation cost: 0.000, Validation F1: 0.839\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "import time\n",
    "for epoch in xrange(epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    start = time.clock()\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(train_X, train_y)):\n",
    "        cost = train(instance_x, instance_y)\n",
    "        if i % 1000 == 0:\n",
    "            print \"EPOCH:: %i, Iteration %i, cost: %.3f\" % (epoch + 1, i, cost)\n",
    "            print \"used time: %.3f\" % (time.clock() - start)\n",
    "            start = time.clock()\n",
    "    \n",
    "    true_y, pred_y, valid_cost = [], [], []\n",
    "    for instance_x, instance_y in zip(valid_X, valid_y):\n",
    "        cost, pred = valid(instance_x, instance_y)\n",
    "        true_y += list(np.argmax(instance_y, axis=1))\n",
    "        pred_y += list(pred)\n",
    "        valid_cost += cost\n",
    "    print 'EPOCH:: %i, Validation cost: %.3f, Validation F1: %.3f' % (epoch + 1, sum(valid_cost), f1_score(true_y, pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83440532691741265"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_y, pred_y = [], []\n",
    "for instance_x, instance_y in zip(test_X, test_y):\n",
    "    pred_y += list(test(instance_x))\n",
    "    true_y += instance_y\n",
    "\n",
    "f1_score(true_y, pred_y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tar cvf ../ci"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
